{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18135fc4",
   "metadata": {
    "id": "18135fc4"
   },
   "source": [
    "# Gretel Trainer\n",
    "\n",
    "This notebook is designed to help users successfully train synthetic models on complex datasets with high row and column counts. The code works by intelligently dividing a dataset into a set of smaller datasets of correlated columns that can be parallelized and then joined together. \n",
    "\n",
    "**Getting started:**\n",
    "\n",
    "\n",
    "*   Copy your [Gretel API](https://console.gretel.cloud) key to the clipboard.\n",
    "*   Update the `DATASET_PATH` to your dataset, or use the provided example.\n",
    "*   Click Runtime -> Run All.\n",
    "*   Use the correlation graph to compare your real world and synthetic data! \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e617d2e3",
   "metadata": {
    "id": "e617d2e3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "!git clone https://github.com/gretelai/trainer.git\n",
    "\n",
    "os.chdir('./trainer')\n",
    "!pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68871bd5",
   "metadata": {
    "id": "68871bd5"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "import pandas as pd\n",
    "\n",
    "from gretel_trainer import strategy, runner\n",
    "\n",
    "from gretel_client import configure_session, ClientConfig\n",
    "from gretel_client.projects import create_or_get_unique_project\n",
    "from gretel_client.projects.models import read_model_config\n",
    "from gretel_client.projects.jobs import Status\n",
    "from gretel_synthetics.utils.header_clusters import cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad5bcf6",
   "metadata": {
    "id": "4ad5bcf6"
   },
   "outputs": [],
   "source": [
    "# Specify your Gretel API key\n",
    "\n",
    "configure_session(ClientConfig(api_key=getpass(prompt=\"Enter Gretel API key\"), \n",
    "                               endpoint=\"https://api.gretel.cloud\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a203bbb8",
   "metadata": {
    "id": "a203bbb8"
   },
   "source": [
    "## Project Settings\n",
    "\n",
    "Use the configuration options below to control parallelization settings.\n",
    "* `MAX_ROWS` sets the maximum number of rows per sub-model, which helps reduce per-job run time and the need to tune neural network parameters such as `learning_rate`, `batch_size`, and `rnn_units` for larger datasets. Typical values are 20,000-100,000 rows.\n",
    "* `MAX_HEADER_CLUSTERS` sets the maximum number of columns to include for each sub-model. Higher values help with maintaining complex correlations in datasets. Try a lower value if you have mixed text and numeric values, or if the model is not generating valid records. Typical values are 10-20 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3b0120",
   "metadata": {
    "id": "1e3b0120"
   },
   "outputs": [],
   "source": [
    "MAX_ROWS = 20000 # Maximum row count per model\n",
    "MAX_HEADER_CLUSTERS = 20 # Max columns per cluster\n",
    "PROJECT_NAME = 'health-data'\n",
    "PROJECT = create_or_get_unique_project(name=PROJECT_NAME)\n",
    "\n",
    "print(f\"Follow model training at: {PROJECT.get_console_url()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae267ea",
   "metadata": {
    "id": "dae267ea"
   },
   "source": [
    "## Dataset Preprocessing\n",
    "\n",
    "Preprocess the data before training the network. A few tips:\n",
    "* Try reducing floating point precision to a consistent number of decimal places (default: 4)\n",
    "* Fields containing complex random numbers (such as UIDs) can be difficult for language models to learn. Try dropping them, specifying them as model seeds to preserve them, or replacing them with a LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc77f34",
   "metadata": {
    "id": "8bc77f34"
   },
   "outputs": [],
   "source": [
    "DATASET_PATH = './data/mitre-synthea-health.csv'\n",
    "ROUND_DECIMALS = 4\n",
    "\n",
    "\n",
    "def preprocess_data(dataset_path: str) -> pd.DataFrame:\n",
    "    tmp = pd.read_csv(dataset_path, low_memory=False)\n",
    "    tmp = tmp.round(ROUND_DECIMALS)\n",
    "    return tmp\n",
    "\n",
    "\n",
    "DF = preprocess_data(DATASET_PATH)\n",
    "DF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9553c7d",
   "metadata": {
    "id": "d9553c7d"
   },
   "source": [
    "## Hyperparameter Settings\n",
    "\n",
    "View example default configs on GitHub https://github.com/gretelai/gretel-blueprints/tree/main/config_templates/gretel/synthetics. A few tips:\n",
    "\n",
    "* For larger dataset sizes (50,000-100,000 rows) try setting `vocab_size` to 20,000. This uses a `sentencepiece` tokenizer and will speed up model training and generation. For smaller datasets or if you're seeing high invalid record counts, use `vocab_size` of 0 to tokenize per character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18926173",
   "metadata": {
    "id": "18926173"
   },
   "outputs": [],
   "source": [
    "# Fine tune any configuration settings here\n",
    "\n",
    "CONFIG = read_model_config(\"synthetics/default\")\n",
    "CONFIG[\"models\"][0][\"synthetics\"][\"params\"][\"vocab_size\"] = 0\n",
    "CONFIG[\"models\"][0][\"synthetics\"][\"params\"][\"learning_rate\"] = 0.001\n",
    "CONFIG[\"models\"][0][\"synthetics\"][\"privacy_filters\"] = {}\n",
    "CONFIG[\"models\"][0][\"synthetics\"][\"privacy_filters\"][\"outliers\"] = None\n",
    "CONFIG[\"models\"][0][\"synthetics\"][\"privacy_filters\"][\"similarity\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645d2859",
   "metadata": {
    "id": "645d2859"
   },
   "outputs": [],
   "source": [
    "# Initialize the parallelization strategy\n",
    "\n",
    "def initialize_run() -> runner.StrategyRunner:\n",
    "    \n",
    "    # Create clusters of correlated columns (might take a few minutes)\n",
    "    plot = True if len(DF.columns) < 50 else False\n",
    "    header_clusters = cluster(DF, maxsize=MAX_HEADER_CLUSTERS, plot=plot) \n",
    "\n",
    "    constraints = strategy.PartitionConstraints(\n",
    "        header_clusters=header_clusters, \n",
    "        max_row_count=MAX_ROWS\n",
    "    )\n",
    "    \n",
    "    run = runner.StrategyRunner(\n",
    "        strategy_id=\"foo\",\n",
    "        df=DF,\n",
    "        cache_file=\"runner.json\",\n",
    "        cache_overwrite=True,  # Set to False to load existing cache (and not start over)\n",
    "        model_config=CONFIG,\n",
    "        partition_constraints=constraints,\n",
    "        project=PROJECT\n",
    "    )    \n",
    "    return run\n",
    "\n",
    "run = initialize_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17f0099",
   "metadata": {
    "id": "e17f0099"
   },
   "outputs": [],
   "source": [
    "# Train all models\n",
    "run.train_all_partitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e67bc9b",
   "metadata": {
    "id": "1e67bc9b"
   },
   "outputs": [],
   "source": [
    "# Access synthetic data\n",
    "\n",
    "synthetic = run.get_training_synthetic_data()\n",
    "synthetic.to_csv('synthetic.csv', index=False)\n",
    "synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1460ea07",
   "metadata": {
    "id": "1460ea07"
   },
   "outputs": [],
   "source": [
    "#Uncomment and run these lines to terminate models training in the cloud\n",
    "\n",
    "#run.cancel_all()\n",
    "#PROJECT.delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45885579",
   "metadata": {
    "id": "45885579"
   },
   "source": [
    "## Plot correlations\n",
    "\n",
    "Use the `_get_correlation_matrix` from `gretel-synthetics` to compare correlations between the real world and synthetic datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfae22c",
   "metadata": {
    "id": "8cfae22c"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from gretel_synthetics.utils.header_clusters import _get_correlation_matrix\n",
    "\n",
    "\n",
    "def plot_correlations(real_df: pd.DataFrame, synthetic_df: pd.DataFrame):\n",
    "    s_corr = _get_correlation_matrix(real_df)\n",
    "    r_corr = _get_correlation_matrix(synthetic_df)\n",
    "\n",
    "    fig = make_subplots(rows=1, cols=2, horizontal_spacing=0.2)\n",
    "    fig.update_layout(title_text=\"Real world vs. Synthetic Correlations\")\n",
    "    trace1 = go.Heatmap(z=r_corr, y=r_corr.index, x=r_corr.columns)\n",
    "    trace2 = go.Heatmap(z=s_corr, y=s_corr.index, x=s_corr.columns)\n",
    "    fig.add_trace(trace1, row=1, col=1)\n",
    "    fig.add_trace(trace2, row=1, col=2)\n",
    "    fig.update_traces(showscale=False)\n",
    "    fig.show()\n",
    "\n",
    "plot_correlations(DF, synthetic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e44df3",
   "metadata": {
    "id": "38e44df3"
   },
   "outputs": [],
   "source": [
    "# Use the model to generate additional data\n",
    "\n",
    "run.generate_data(num_records=5000, max_invalid=None, clear_cache=True)\n",
    "run.get_synthetic_data()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "gretel-trainer.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
